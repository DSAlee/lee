一：DDL

规定数据库DBlee，表TBlee，
hive数据库创建：hive数据存储在hdfs上，使用hdfs作为数据存储
创建数据库的语句：
create database if not exists DBlee
location '/user/hive/DBLEE.db'
所创建的数据库（命名空间）:/hive.metestore.warehouse.dir中定义的目录下/DBLEE.db/DBLee
Hive所管理的所有数据都存储在使用hive定义的顶层目录下，即hive-site.xml文件中metastore.warehouse.dir的参数配置
创建完数据库之后可以使用：
describe database extended DBlee;来查看数据库的属性；
show databases like '*lee*'；来列出Metastore中所有的数据库
一旦创建了数据库之后，就可以修改数据库的元数据的属性：
alter database DBLee
set dbproperties/owner （'department'='sales'）;
也可以删除数据库：
drop database DBlee []/[cascade]/[restrict]
csacade:删除数据库，连同数据库里面的表（外部表，内部表）也一起删除；
restrict：删除数据库时，如果数据库中有表则将删除失败，同不写的时候的默认行为

二：hive所支持的数据类型：
数组，Map，结构体，联合体
 数组：由一组数据类型的数据元素构成的有序数据复合集
stringitems Array <"this is a element","this is a array","i am not null">
字符串数组在定义赋值完成之后，可以通过下标索引进行数据的精确获取
stringitems[0],,,,,
   
  Map：是无序键/值对集合，键可以是hive所支持的任意一种简单数据类型，值可以是简单类型或者复杂数据类型
  Map的数据元素的访问需要使用值对应的键来访问
Basketmap MAP<'string','iam a basket'>
Basketmap MAP<"Eggs",'12'>
数据是通过map（）函数完成存储和输出显示的
Basketmap("Eggs") returns 12

结构体：
结构体是一个对象，其中含有多个字段，这些字段又可以是任何数据类型
结构体的定义：
 address STRUCT<housenum:String,street:String,city:String,country:String,Zipcode:INT>
结构体对象的赋值：
address<"17","martiingStreeet","SFLSIS","USA",271000>
可以使用结构体加点加字段的方式来获取每一个值：
address.zipcode可以访问到邮政编码

联合体：
将不同数据类型的元素存储在同一字段的不同行中

三：表
Hive数据模型包含一个数据的逻辑行/列视图，被称作表，数据却是独立于表存在
hive中的数据存贮在HDFS目录的文件里，表的定义存在在一个名为HCatalog的关系数据库中存储
hive的表不同于关系数据库的表：
hive的表可以和数据保持松耦合的数据关系，如果是外部表，则删除表，不会删除底层的数据，而关系数据库的表在删除时会删除表定义和底层数据
Hive建表时：
在创建表的过程中所指定的配置定义了Hive应该如何解释存储在HDFS数据文件中的底层数据，HIve中内置了很多数据格式解释器，也可以自己定义序列化和反序列化
器，在创建表的时候，使用create table 加载并理解数据格式。


3.1内部表，外部表
使用内部表：
使用方式：将数据放到HDFS的指定目录下，在HIve中在同指定目录下创建内部表，使得表可以使用此数据，重点是相同目录
hadoop fs -put /tmp/status.txt /user/demo/status/
hadoop fs -ks /user/demo/status
-rw-r--r-- /user/demo/status/status.txt
首先创建内部表来访问文件status.txt中的数据
create table statusinnerTable(stata string) location '/user/demo/status/';
（将内部表指向数据的存储位置）
此时可以对数据做处理：
describe formatted statusinnerTable;

select * from statusinnerTable;

另外如果在创建一个内部表时不指定任何位置，Hive将在默认的Hive目录下存放该表的数据！ 

在此目录下添加其他的数据文件，也会通过SQL语句从表中查询出来，这是因为在创建表的时候指定该目录为存放数据的位置。

创建外部表：
create  external table statusexternalTable（state string） location '/user/demo/status';

select * from statusexternalTable ;

现在在统一数据集上有了两张表，通过两张表都可以查询到数据。
HIve能够控制内部表和底层数据，hive对外部表的控制程度时松耦合是的


3.2

分区和分桶
分区键区别于关系数据库的点：
数据依据分区键被分割成若干逻辑块并被单独存放在单独路径里面；单独的分区路径是由表路径加分区键组成的目录层结构；
创建分区表的分区键是表中的字段，且作为目录名称，所以在分区下表文件中不存在该字段，而关系型数据库在create table结构中必须存在该分区键
当查询分区表时，查询结果时满足分区键对应的列的值的所有行结果

创建分区表需要预先为底层分区创建目录结构、当使用Insert命令将数据长插入到内部表的新建的分区时，系统会为该新分区自动创建
Insert into statusinnerTable partion(store="new yaro") values(""); 
分区数据注意事项：
如果创建了很多分区并且每个分区都含有很多小数据块

分桶：
创建一个分桶表，将创建的表的某个属性列作为分桶列：
create external table customers（
custid int，
fname String，
iname String,
city  String,
state  String
)clustered by (custid) into 11 buckets
location '/user/demo/customers';
在进行桶表创建的时候，分桶字段是包含在表里面的





